{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Programming_students_task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikitaker/Q-learning/blob/master/Programming_students_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9QLe_T6GZUd",
        "colab_type": "text"
      },
      "source": [
        "# Задание на программирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDQzNIZXAoFE",
        "colab_type": "text"
      },
      "source": [
        "Зададим гиперпараметры модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOMw2ZbOAmOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon = 0.1 # Параметр эпсилон при использовании эпсилон жадной стратегии\n",
        "gamma = 0.8 # Коэффциент дисконтирования гамма\n",
        "random_seed = 3 #Random seed\n",
        "time_delay = 1 # Задержка времени при отрисовке процесса игры после обучения (секунды) \n",
        "lr_rate = 0.9 #Коэффициент скорости обучения альфа"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awL7CCCwD6C3",
        "colab_type": "code",
        "outputId": "8f2e4886-361b-42f4-b400-7f8258934c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def generate_random_map(size, p, sd):\n",
        "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
        "    :param size: size of each side of the grid\n",
        "    :param p: probability that a tile is frozen\n",
        "    \"\"\"\n",
        "    valid = False\n",
        "    np.random.seed(sd)\n",
        "\n",
        "    # DFS to check that it's a valid path.\n",
        "    def is_valid(res):\n",
        "        frontier, discovered = [], set()\n",
        "        frontier.append((0,0))\n",
        "        while frontier:\n",
        "            r, c = frontier.pop()\n",
        "            if not (r,c) in discovered:\n",
        "                discovered.add((r,c))\n",
        "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
        "                for x, y in directions:\n",
        "                    r_new = r + x\n",
        "                    c_new = c + y\n",
        "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
        "                        continue\n",
        "                    if res[r_new][c_new] == 'G':\n",
        "                        return True\n",
        "                    if (res[r_new][c_new] not in '#H'):\n",
        "                        frontier.append((r_new, c_new))\n",
        "        return False\n",
        "\n",
        "    while not valid:\n",
        "        p = min(1, p)\n",
        "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
        "        res[0][0] = 'S'\n",
        "        res[-1][-1] = 'G'\n",
        "        valid = is_valid(res)\n",
        "    return [\"\".join(x) for x in res]\n",
        "\n",
        "#Генерация карты\n",
        "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) #Создаем свою карту\n",
        "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #Инициализируем среду\n",
        "print(\"Ваша карта\")\n",
        "env.render() #Выводим карту на экран"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ваша карта\n",
            "\n",
            "\u001b[41mS\u001b[0mFFFHH\n",
            "FFFFFF\n",
            "FFFFFF\n",
            "FFFFFF\n",
            "FFFFFH\n",
            "HFHHFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDCexoEU9a_c",
        "colab_type": "text"
      },
      "source": [
        "Функции выбора действия и обновления таблицы ценности действий. Строчка *** используется для того, чтобы проверять ответы в openedx. Вне рамках академической задачи лучше использовать оригинальный метод класса `environment`, то есть:\n",
        "\n",
        "`action = env.action_space.sample()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdQBpxaTOK7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_action(state):\n",
        "    action=0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = np.random.randint(0,env.action_space.n) #***\n",
        "    else:\n",
        "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "def learn(state, state2, reward, action, done):\n",
        "    target = reward + gamma*np.max(Q[state2])\n",
        "    error = target - Q[state, action]\n",
        "    Q[state, action] += lr_rate*error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq92-dWiOchF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "# Inititalization\n",
        "np.random.seed(random_seed)\n",
        "total_games = 10000\n",
        "max_steps = 100\n",
        "won = 0\n",
        "isFirst = True\n",
        "streak = 0\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "#Main cycle\n",
        "for game in tqdm(range(total_games)):\n",
        "    state = env.reset()\n",
        "    t = 0\n",
        "    while t < max_steps:\n",
        "        \n",
        "        t += 1\n",
        "\n",
        "        action = choose_action(state)\n",
        "\n",
        "        state2, reward, done, info = env.step(action)\n",
        "        \n",
        "        if t == max_steps:\n",
        "          done = True  \n",
        "\n",
        "        learn(state, state2, reward, action, done)\n",
        "\n",
        "        state = state2\n",
        "\n",
        "        if done:\n",
        "          \n",
        "          if reward == 1:\n",
        "            won += 1\n",
        "            if isFirst:\n",
        "              streak += 1\n",
        "          else:\n",
        "            streak = 0\n",
        "\n",
        "          if streak == 5:\n",
        "            streak_num = game + 1\n",
        "            isFirst = False\n",
        "            streak = 0\n",
        "          \n",
        "          break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZbJtFnhLa7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f7ba0e7-8c54-4832-e5d3-42a590bafbf3"
      },
      "source": [
        "print(\"Количество побед в серии из 10 000 игр: \", won)\n",
        "print(\"Пять побед подряд впервые было одержано в игре \", streak_num)\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество побед в серии из 10 000 игр:  9116\n",
            "Пять побед подряд впервые было одержано в игре  31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ysllZjEQXLa",
        "colab_type": "code",
        "outputId": "38b5e085-14e1-4b92-a989-337f135f8c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import time\n",
        "#Жадный выбор действий\n",
        "def choose_action_one_game(state):\n",
        "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "states=[]#Массив для сохранения состояний агента в течение игры\n",
        "t = 0\n",
        "state = env.reset()\n",
        "wn = 0\n",
        "while(t<100):\n",
        "  env.render()\n",
        "  time.sleep(time_delay)\n",
        "  clear_output(wait=True)\n",
        "  action = choose_action_one_game(state)  \n",
        "  state2, reward, done, info = env.step(action)  \n",
        "  states.append(state)\n",
        "  state = state2\n",
        "  t += 1\n",
        "  if done and reward == 1:\n",
        "    wn=1\n",
        "  if done:\n",
        "    break\n",
        "if wn == 1:\n",
        "  print(\"!!!Победа!!!\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!!!Победа!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKMCMdpOTcXy",
        "colab_type": "code",
        "outputId": "cca8ffbd-2f1d-4f8e-f516-80a558e132e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_maze_pic(maze):\n",
        "  maze_pic=[]\n",
        "  for i in range(len(maze)):\n",
        "    row = []\n",
        "    for j in range(len(maze[i])):\n",
        "      if maze[i][j] == 'S':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'F':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'H':\n",
        "        row.append(1)\n",
        "      if maze[i][j] == 'G':\n",
        "        row.append(0)\n",
        "    maze_pic.append(row)\n",
        "  maze_pic = np.array(maze_pic)\n",
        "  return maze_pic\n",
        "  \n",
        "\n",
        "#Make maze fit to plot\n",
        "maze_pic = make_maze_pic(random_map)\n",
        "nrows, ncols = maze_pic.shape\n",
        "\n",
        "#Arrays of picture elements\n",
        "rw = np.remainder(states,nrows)\n",
        "cl = np.floor_divide(states,nrows)\n",
        "if wn == 1:\n",
        "  rw = np.append(rw, [nrows-1])\n",
        "  cl = np.append(cl,[ncols-1])\n",
        "\n",
        "#Picture plotting\n",
        "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
        "ax1.clear()\n",
        "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
        "ax1.set_xticklabels([])\n",
        "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
        "ax1.set_yticklabels([])\n",
        "ax1.grid(True)\n",
        "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
        "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
        "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
        "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
        "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
        "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
        "ax1.imshow(maze_pic, cmap=\"binary\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fae7ea69fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjaiFzMng7pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_action(state):\n",
        "    action=0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = np.random.randint(0,env.action_space.n) #***\n",
        "    else:\n",
        "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "def learn(state, state2, reward, action, action2, done):\n",
        "    if done:\n",
        "      Q[state, action] += lr_rate * ( reward  - Q[state, action] )\n",
        "    else:\n",
        "      Q[state, action] += lr_rate * ( reward + (gamma * Q[state2, action2] ) - Q[state, action] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL1mIHjPpOpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "np.random.seed(random_seed)\n",
        "total_games = 40000\n",
        "max_steps = 100\n",
        "won = 0\n",
        "isFirst = True\n",
        "streak = 0\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "#Main cycle\n",
        "for game in tqdm(range(total_games)):\n",
        "    state = env.reset()\n",
        "    t = 0\n",
        "    action = choose_action(state)\n",
        "    while t < max_steps:\n",
        "              \n",
        "        t += 1\n",
        "\n",
        "        state2, reward, done, info = env.step(action)\n",
        "\n",
        "        action2 = choose_action(state2)\n",
        "\n",
        "        if t == max_steps:\n",
        "          done = True  \n",
        "\n",
        "        learn(state, state2, reward, action, action2, done) \n",
        "\n",
        "        state = state2\n",
        "        action = action2\n",
        "\n",
        "        if done:\n",
        "          if reward == 1:\n",
        "            won += 1\n",
        "            if isFirst:\n",
        "              streak += 1\n",
        "          else:\n",
        "            streak = 0\n",
        "\n",
        "          if streak == 5:\n",
        "            streak_num = game + 1\n",
        "            isFirst = False\n",
        "            streak = 0\n",
        "\n",
        "          break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4pSaSSKickL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0c1dd587-e253-495a-d73e-373fa3a16455"
      },
      "source": [
        "print(\"Количество побед в серии из 40 000 игр: \", won)\n",
        "print(\"Пять побед подряд впервые было одержано в игре \", streak_num)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество побед в серии из 40 000 игр:  36020\n",
            "Пять побед подряд впервые было одержано в игре  91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_1yiANdkApV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f34f6fc-5952-4510-f43b-a9bff95bdf2d"
      },
      "source": [
        "import time\n",
        "#Жадный выбор действий\n",
        "def choose_action_one_game(state):\n",
        "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "states=[]#Массив для сохранения состояний агента в течение игры\n",
        "t = 0\n",
        "state = env.reset()\n",
        "wn = 0\n",
        "while(t<100):\n",
        "  env.render()\n",
        "  time.sleep(time_delay)\n",
        "  clear_output(wait=True)\n",
        "  action = choose_action_one_game(state)  \n",
        "  state2, reward, done, info = env.step(action)  \n",
        "  states.append(state)\n",
        "  state = state2\n",
        "  t += 1\n",
        "  if done and reward == 1:\n",
        "    wn=1\n",
        "  if done:\n",
        "    break\n",
        "if wn == 1:\n",
        "  print(\"!!!Победа!!!\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!!!Победа!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR5m7QrBkHHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "8ec144a5-c3a9-4dad-87d5-445a93a226cd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_maze_pic(maze):\n",
        "  maze_pic=[]\n",
        "  for i in range(len(maze)):\n",
        "    row = []\n",
        "    for j in range(len(maze[i])):\n",
        "      if maze[i][j] == 'S':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'F':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'H':\n",
        "        row.append(1)\n",
        "      if maze[i][j] == 'G':\n",
        "        row.append(0)\n",
        "    maze_pic.append(row)\n",
        "  maze_pic = np.array(maze_pic)\n",
        "  return maze_pic\n",
        "  \n",
        "\n",
        "#Make maze fit to plot\n",
        "maze_pic = make_maze_pic(random_map)\n",
        "nrows, ncols = maze_pic.shape\n",
        "\n",
        "#Arrays of picture elements\n",
        "rw = np.remainder(states,nrows)\n",
        "cl = np.floor_divide(states,nrows)\n",
        "if wn == 1:\n",
        "  rw = np.append(rw, [nrows-1])\n",
        "  cl = np.append(cl,[ncols-1])\n",
        "\n",
        "#Picture plotting\n",
        "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
        "ax1.clear()\n",
        "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
        "ax1.set_xticklabels([])\n",
        "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
        "ax1.set_yticklabels([])\n",
        "ax1.grid(True)\n",
        "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
        "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
        "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
        "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
        "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
        "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
        "ax1.imshow(maze_pic, cmap=\"binary\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fae7e9e25c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}